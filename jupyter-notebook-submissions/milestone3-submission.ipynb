{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTerrier Notebook for Full-Rank Submissions\n",
    "\n",
    "This notebook serves as a baseline full-rank submission for [TIRA](https://tira.io)/[TIREx](https://tira.io/tirex) that builds a PyTerrier index and subsequently creates a run with BM25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Ensure Libraries are Imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-terrier\n",
      "  Downloading python-terrier-0.10.0.tar.gz (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tira==0.0.88\n",
      "  Downloading tira-0.0.88-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting ir_datasets\n",
      "  Downloading ir_datasets-0.5.5-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests==2.*,>=2.26 in /home/codespace/.local/lib/python3.10/site-packages (from tira==0.0.88) (2.31.0)\n",
      "Collecting docker==6.*,>=6.0.0 (from tira==0.0.88)\n",
      "  Downloading docker-6.1.3-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (from tira==0.0.88) (2.1.2)\n",
      "Requirement already satisfied: packaging>=14.0 in /home/codespace/.local/lib/python3.10/site-packages (from docker==6.*,>=6.0.0->tira==0.0.88) (23.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/codespace/.local/lib/python3.10/site-packages (from docker==6.*,>=6.0.0->tira==0.0.88) (2.0.7)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/codespace/.local/lib/python3.10/site-packages (from docker==6.*,>=6.0.0->tira==0.0.88) (1.6.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests==2.*,>=2.26->tira==0.0.88) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests==2.*,>=2.26->tira==0.0.88) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests==2.*,>=2.26->tira==0.0.88) (2023.7.22)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from python-terrier) (1.26.1)\n",
      "Collecting wget (from python-terrier)\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tqdm (from python-terrier)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyjnius>=1.4.2 (from python-terrier)\n",
      "  Downloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting matchpy (from python-terrier)\n",
      "  Downloading matchpy-0.5.5-py3-none-any.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.10/site-packages (from python-terrier) (1.3.2)\n",
      "Collecting deprecated (from python-terrier)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting chest (from python-terrier)\n",
      "  Downloading chest-0.2.3.tar.gz (9.6 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from python-terrier) (1.11.3)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.10/site-packages (from python-terrier) (1.3.2)\n",
      "Collecting nptyping==1.4.4 (from python-terrier)\n",
      "  Downloading nptyping-1.4.4-py3-none-any.whl (31 kB)\n",
      "Collecting more-itertools (from python-terrier)\n",
      "  Downloading more_itertools-10.1.0-py3-none-any.whl.metadata (33 kB)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from python-terrier) (3.1.2)\n",
      "Collecting statsmodels (from python-terrier)\n",
      "  Downloading statsmodels-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting ir-measures>=0.3.1 (from python-terrier)\n",
      "  Downloading ir_measures-0.3.3.tar.gz (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting dill (from python-terrier)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting pytrec-eval-terrier>=0.5.3 (from python-terrier)\n",
      "  Downloading pytrec_eval_terrier-0.5.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (777 bytes)\n",
      "Collecting typish>=1.7.0 (from nptyping==1.4.4->python-terrier)\n",
      "  Downloading typish-1.9.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /home/codespace/.local/lib/python3.10/site-packages (from ir_datasets) (4.12.2)\n",
      "Collecting inscriptis>=2.2.0 (from ir_datasets)\n",
      "  Downloading inscriptis-2.3.2-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m964.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lxml>=4.5.2 (from ir_datasets)\n",
      "  Downloading lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from ir_datasets) (6.0.1)\n",
      "Collecting trec-car-tools>=2.5.4 (from ir_datasets)\n",
      "  Downloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
      "Collecting lz4>=3.1.10 (from ir_datasets)\n",
      "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting warc3-wet>=0.2.3 (from ir_datasets)\n",
      "  Downloading warc3_wet-0.2.3-py3-none-any.whl (13 kB)\n",
      "Collecting warc3-wet-clueweb09>=0.2.5 (from ir_datasets)\n",
      "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting zlib-state>=0.1.3 (from ir_datasets)\n",
      "  Downloading zlib-state-0.1.6.tar.gz (9.5 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ijson>=3.1.3 (from ir_datasets)\n",
      "  Downloading ijson-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting pyautocorpus>=0.1.1 (from ir_datasets)\n",
      "  Downloading pyautocorpus-0.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting unlzw3>=0.2.1 (from ir_datasets)\n",
      "  Downloading unlzw3-0.2.2-py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.10/site-packages (from beautifulsoup4>=4.4.1->ir_datasets) (2.5)\n",
      "Collecting cwl-eval>=1.0.10 (from ir-measures>=0.3.1->python-terrier)\n",
      "  Downloading cwl-eval-1.0.12.tar.gz (31 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir_datasets)\n",
      "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting heapdict (from chest->python-terrier)\n",
      "  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated->python-terrier)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->python-terrier) (2.1.3)\n",
      "Collecting multiset<3.0,>=2.0 (from matchpy->python-terrier)\n",
      "  Downloading multiset-2.1.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->tira==0.0.88) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->tira==0.0.88) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->tira==0.0.88) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn->python-terrier) (3.2.0)\n",
      "Collecting patsy>=0.5.2 (from statsmodels->python-terrier)\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.8/233.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels->python-terrier) (1.16.0)\n",
      "Downloading tira-0.0.88-py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m886.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ir_datasets-0.5.5-py3-none-any.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.0/318.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ijson-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyautocorpus-0.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (379 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytrec_eval_terrier-0.5.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading more_itertools-10.1.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: python-terrier, ir-measures, warc3-wet-clueweb09, zlib-state, chest, wget, cbor, cwl-eval\n",
      "  Building wheel for python-terrier (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-terrier: filename=python_terrier-0.10.0-py3-none-any.whl size=115530 sha256=6bfa301f9795bc5fe16c144c85c9f15d6b2e3870966f579ac1fd4a89e41ed9fe\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/79/7c/8f/679a982895c53af35178eceda648a4bc9a9af6af5542e31a0e\n",
      "  Building wheel for ir-measures (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ir-measures: filename=ir_measures-0.3.3-py3-none-any.whl size=61183 sha256=f186cc349455ffd8919d953ed4d279b856c1602e0c05b6341a25bc052d93bc0c\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/9f/0e/22/718279f23fef1673a4c5e433881c25080a6afaa147e007183e\n",
      "  Building wheel for warc3-wet-clueweb09 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18919 sha256=e5bb0f3df28c15e309eaf62b9595c9fb2c739049a9671f90f378de9f3c60ce87\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/1a/d7/91/7ffb991df87e62355d945745035470ba2616aa3d83a250b5f9\n",
      "  Building wheel for zlib-state (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for zlib-state: filename=zlib_state-0.1.6-cp310-cp310-linux_x86_64.whl size=26683 sha256=17fc99d8576d908e1ee45e5bbef5bad0fb1b6aa37d26181bda50895007647481\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/32/72/7e/aff80f26e926b6e1fb08dfb52aba03c0e058f5e2258deb50a9\n",
      "  Building wheel for chest (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for chest: filename=chest-0.2.3-py3-none-any.whl size=7614 sha256=df994385d3e8e9dbe795a6b6d7fcf8f5f1707d3a9912e2e986a9e3f7bbbc4ff1\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/88/cf/99/4773b31f855f9ecedc32a0ae400f7a4a3001b37c439b6d1a73\n",
      "  Building wheel for wget (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=3fa3079e648e82d74131f7413191f051b8bcc8ccaf290697c60e76dde8242013\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
      "  Building wheel for cbor (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=59431 sha256=4c21327b00442975c8b2ca5ad55cc4312392c6802aff74a17600f6c2d7d9b001\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\n",
      "  Building wheel for cwl-eval (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cwl-eval: filename=cwl_eval-1.0.12-py3-none-any.whl size=38068 sha256=2c3181eb661a5085d2d340a1e1988e3754a17f03d6caa5a208d5f6e6c3af9808\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/3d/c1/94/94a3e5379b1aa8fb7c7f1ad1956305d5edc98ef745b6067d87\n",
      "Successfully built python-terrier ir-measures warc3-wet-clueweb09 zlib-state chest wget cbor cwl-eval\n",
      "Installing collected packages: wget, warc3-wet-clueweb09, warc3-wet, typish, pyjnius, multiset, ijson, heapdict, cbor, zlib-state, wrapt, unlzw3, trec-car-tools, tqdm, pytrec-eval-terrier, pyautocorpus, patsy, nptyping, more-itertools, matchpy, lz4, lxml, dill, cwl-eval, chest, ir-measures, inscriptis, docker, deprecated, tira, statsmodels, ir_datasets, python-terrier\n",
      "Successfully installed cbor-1.0.0 chest-0.2.3 cwl-eval-1.0.12 deprecated-1.2.14 dill-0.3.7 docker-6.1.3 heapdict-1.0.1 ijson-3.2.3 inscriptis-2.3.2 ir-measures-0.3.3 ir_datasets-0.5.5 lxml-4.9.3 lz4-4.3.2 matchpy-0.5.5 more-itertools-10.1.0 multiset-2.1.1 nptyping-1.4.4 patsy-0.5.3 pyautocorpus-0.1.12 pyjnius-1.6.1 python-terrier-0.10.0 pytrec-eval-terrier-0.5.6 statsmodels-0.14.0 tira-0.0.88 tqdm-4.66.1 trec-car-tools-2.6 typish-1.9.3 unlzw3-0.2.2 warc3-wet-0.2.3 warc3-wet-clueweb09-0.2.5 wget-3.2 wrapt-1.16.0 zlib-state-0.1.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Detect if we are in the TIRA sandbox\n",
    "# Install the required dependencies if we are not in the sandbox.\n",
    "if 'TIRA_DATASET_ID' not in os.environ:\n",
    "    !pip3 install python-terrier tira==0.0.88 ir_datasets\n",
    "else:\n",
    "    print('We are in the TIRA sandbox.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to execution in TIRA, I have patched ir_datasets to always return the single input dataset mounted to the sandbox.\n",
      "Start PyTerrier with version=5.7, helper_version=0.0.7, no_download=True\n",
      "terrier-assemblies 5.7 jar-with-dependencies not found, downloading to /home/codespace/.pyterrier...\n"
     ]
    }
   ],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "\n",
    "# this loads and starts pyterrier so that it also works in the TIRA\n",
    "ensure_pyterrier_is_loaded()\n",
    "\n",
    "# PyTerrier must be imported after the call to ensure_pyterrier_is_loaded in TIRA.\n",
    "import pyterrier as pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pt.get_dataset('irds:ir-lab-jena-leipzig-wise-2023/training-20231104-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See the first two queries:\n",
      "         qid        query\n",
      "0  q06223196  car shelter\n",
      "1    q062228      airport\n"
     ]
    }
   ],
   "source": [
    "print('See the first two queries:')\n",
    "topics = data.get_topics('title')\n",
    "print(topics.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build index:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ir-lab-jena-leipzig-wise-2023/training-20231104-training documents: 100%|██████████| 47064/47064 [00:44<00:00, 1055.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Index is created\n"
     ]
    }
   ],
   "source": [
    "print('Build index:')\n",
    "\"\"\"\n",
    "Function: pt.IterDictIndexer\n",
    "Purpose: Creates an indexer for building an index from an iterable of documents.\n",
    "\n",
    "Parameters:\n",
    "    1. index_path (str): Specifies the directory where the index will be stored.\n",
    "       - \"/tmp/index\": In this case, the index is stored in the '/tmp/index' directory.\n",
    "\n",
    "    2. meta (dict): A dictionary specifying the metadata fields to be stored alongside the index.\n",
    "       - {'docno': 100}: This indicates that the 'docno' field is included as metadata with a maximum length of 100 characters.\n",
    "       - (test with text length differences)\n",
    "       - Note: 'docno' typically represents a unique document identifier.\n",
    "\n",
    "    3. verbose (bool): Controls the verbosity of the output during indexing.\n",
    "       - True: Enables verbose output, providing detailed information during the indexing process.\n",
    "\n",
    "    4. overwrite (bool): Determines whether to overwrite an existing index in the specified path.\n",
    "       - True: If an index already exists at the specified path, it will be overwritten.\n",
    "\n",
    "    5. stemmer (str): Specifies the stemmer/lemmatizer to be used for text normalization.\n",
    "       - 'StanfordLemmatizer': Utilizes the Stanford Lemmatizer for text normalization, which is more sophisticated than simple stemming, as it considers the context of words to reduce them to their base or dictionary form.\n",
    "\n",
    "Usage:\n",
    "    - This line initializes an indexer that will create an index at '/tmp/index'.\n",
    "    - The indexer includes document number metadata, provides verbose output, overwrites any existing index at the location, and uses the Stanford Lemmatizer for text normalization.\n",
    "\"\"\"\n",
    "iter_indexer = pt.IterDictIndexer(\"/tmp/index\", meta={'docno': 100}, verbose=True, overwrite=True, stemmer='EnglishSnowballStemmer')\n",
    "!rm -Rf /tmp/index\n",
    "indexref = iter_indexer.index(data.get_corpus_iter())\n",
    "\n",
    "print('Done. Index is created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create the Retrieval Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using tutorial 6, we chose the parameters from the best run using the *validation* dataset. Therefore b is 0.8 and k_1 is 1.2.\n",
    "\"\"\"\n",
    "b = 0.8\n",
    "k_1 = 1.2\n",
    "\n",
    "configuration = {\"bm25.b\" : b, \"bm25.k_1\": k_1}\n",
    "bm25 = pt.BatchRetrieve(indexref, wmodel=\"BM25\", verbose=True, controls=configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create the Run and Persist the Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 672/672 [00:14<00:00, 46.86q/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, run was created\n"
     ]
    }
   ],
   "source": [
    "print('Create run')\n",
    "run = bm25(topics)\n",
    "print('Done, run was created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** once proper evaluation is implemented:\n",
    "- Query Expansion ([documentaion](http://terrier.org/docs/v4.1/javadoc/org/terrier/matching/models/queryexpansion/Bo1.html))\n",
    "- Query Segmentation\n",
    "\n",
    "Reason:  \n",
    "Right now we could easily implement those things, but without having a proper system set up to **compare and understand** the results, it will not yield useful results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. run file is stored under \"./runs_milestone3/2023-11-20_14-49-19-run.txt\".\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "run_time = datetime.datetime.now()\n",
    "formatted_datetime = run_time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "file_name = f'./runs_milestone3/{formatted_datetime}-run.txt'\n",
    "\n",
    "file_name = './run.txt'\n",
    "\n",
    "persist_and_normalize_run(run, 'bm25-baseline', default_output=file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
